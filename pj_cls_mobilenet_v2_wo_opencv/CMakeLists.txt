cmake_minimum_required(VERSION 3.0)

# Create project
set(ProjectName "main")
project(${ProjectName})
set_property(DIRECTORY ${CMAKE_CURRENT_SOURCE_DIR} PROPERTY VS_STARTUP_PROJECT ${ProjectName})

# Select build system and set compile options
include(${CMAKE_CURRENT_LIST_DIR}/../common_helper/cmakes/build_setting.cmake)

# Create executable file
add_executable(${ProjectName} main.cpp)

# Use stb
target_include_directories(${ProjectName} PUBLIC ${CMAKE_CURRENT_LIST_DIR}/third_party/stb)

# Link Common Helper module
set(COMMON_HELPER_WITH_OPENCV off CACHE BOOL "With OpenCV? [on/off]")
add_subdirectory(${CMAKE_CURRENT_LIST_DIR}/../common_helper common_helper)
target_include_directories(${ProjectName} PUBLIC ${CMAKE_CURRENT_LIST_DIR}/../common_helper)
target_link_libraries(${ProjectName} CommonHelper)

# For InferenceHelper
set(INFERENCE_HELPER_DIR ${CMAKE_CURRENT_LIST_DIR}/../InferenceHelper/)
add_subdirectory(${INFERENCE_HELPER_DIR}/inference_helper inference_helper)
target_include_directories(${ProjectName} PUBLIC ${INFERENCE_HELPER_DIR}/inference_helper)
target_link_libraries(${ProjectName} InferenceHelper)

# Add definition to select framework automatically. You don't need this in the real product
if(INFERENCE_HELPER_ENABLE_OPENCV)
    add_definitions(-DINFERENCE_HELPER_ENABLE_OPENCV)
endif()
if(INFERENCE_HELPER_ENABLE_TENSORRT)
    add_definitions(-DINFERENCE_HELPER_ENABLE_TENSORRT)
endif()
if(INFERENCE_HELPER_ENABLE_TFLITE)
    add_definitions(-DINFERENCE_HELPER_ENABLE_TFLITE)
endif()
if(INFERENCE_HELPER_ENABLE_TFLITE_DELEGATE_GPU)
    add_definitions(-DINFERENCE_HELPER_ENABLE_TFLITE_DELEGATE_GPU)
endif()
if(INFERENCE_HELPER_ENABLE_TFLITE_DELEGATE_EDGETPU)
    add_definitions(-DINFERENCE_HELPER_ENABLE_TFLITE_DELEGATE_EDGETPU)
endif()
if(INFERENCE_HELPER_ENABLE_TFLITE_DELEGATE_XNNPACK)
    add_definitions(-DINFERENCE_HELPER_ENABLE_TFLITE_DELEGATE_XNNPACK)
endif()
if(INFERENCE_HELPER_ENABLE_TFLITE_DELEGATE_NNAPI)
    add_definitions(-DINFERENCE_HELPER_ENABLE_TFLITE_DELEGATE_NNAPI)
endif()
if(INFERENCE_HELPER_ENABLE_NCNN)
    add_definitions(-DINFERENCE_HELPER_ENABLE_NCNN)
endif()
if(INFERENCE_HELPER_ENABLE_MNN)
    add_definitions(-DINFERENCE_HELPER_ENABLE_MNN)
endif()
if(INFERENCE_HELPER_ENABLE_SNPE)
	add_definitions(-DINFERENCE_HELPER_ENABLE_SNPE)
endif()
if(INFERENCE_HELPER_ENABLE_ARMNN)
	add_definitions(-DINFERENCE_HELPER_ENABLE_ARMNN)
endif()
if(INFERENCE_HELPER_ENABLE_NNABLA)
    add_definitions(-DINFERENCE_HELPER_ENABLE_NNABLA)
endif()
if(INFERENCE_HELPER_ENABLE_NNABLA_CUDA)
    add_definitions(-DINFERENCE_HELPER_ENABLE_NNABLA_CUDA)
endif()
if(INFERENCE_HELPER_ENABLE_ONNX_RUNTIME)
    add_definitions(-DINFERENCE_HELPER_ENABLE_ONNX_RUNTIME)
endif()
if(INFERENCE_HELPER_ENABLE_ONNX_RUNTIME_CUDA)
    add_definitions(-DINFERENCE_HELPER_ENABLE_ONNX_RUNTIME_CUDA)
endif()
if(INFERENCE_HELPER_ENABLE_LIBTORCH)
    add_definitions(-DINFERENCE_HELPER_ENABLE_LIBTORCH)
endif()
if(INFERENCE_HELPER_ENABLE_LIBTORCH_CUDA)
    add_definitions(-DINFERENCE_HELPER_ENABLE_LIBTORCH_CUDA)
endif()
if(INFERENCE_HELPER_ENABLE_TENSORFLOW)
    add_definitions(-DINFERENCE_HELPER_ENABLE_TENSORFLOW)
endif()
if(INFERENCE_HELPER_ENABLE_TENSORFLOW_GPU)
    add_definitions(-DINFERENCE_HELPER_ENABLE_TENSORFLOW_GPU)
endif()

# Copy resouce
file(COPY ${CMAKE_CURRENT_LIST_DIR}/../resource DESTINATION ${CMAKE_BINARY_DIR}/)
add_definitions(-DRESOURCE_DIR="${CMAKE_BINARY_DIR}/resource/")

